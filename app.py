#!/usr/bin/env python3
"""
Audio Processing App - Zen Mode (Final Fix)
"""
from nicegui import ui, app
from pydub import AudioSegment
from pydub.effects import normalize, compress_dynamic_range
import io
import base64
from pathlib import Path
import asyncio
import subprocess
import tempfile
import os

# Global state
state = {
    'original_file': None,
    'original_filename': None,
    'processed_file': None,
    'processed_filename': None,
    'main_card': None
}

def download_bytes(data: bytes, filename: str):
    """Helper: Download in-memory bytes using JavaScript"""
    b64 = base64.b64encode(data).decode()
    ui.run_javascript(f'''
        const link = document.createElement("a");
        link.href = "data:audio/mpeg;base64,{b64}";
        link.download = "{filename}";
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
    ''')

def process_sound_rescue(audio: AudioSegment) -> AudioSegment:
    audio = normalize(audio, headroom=0.1)
    return compress_dynamic_range(audio, threshold=-20.0, ratio=3.0, attack=5.0, release=50.0)

def process_dynamic_balance(audio: AudioSegment) -> AudioSegment:
    """
    Dynamic Balance V3: The 'Broadcast Standard' (EBU R128 Loudnorm)
    Uses FFmpeg's specialized filter for perceived loudness normalization.
    Target: -16 LUFS (Podcast Standard)
    """
    # 1. åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥ä¸­è½¬æ•°æ®
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_in, \
         tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_out:
        
        input_path = temp_in.name
        output_path = temp_out.name
        
        # 2. æŠŠå½“å‰éŸ³é¢‘å¯¼å‡ºåˆ°ä¸´æ—¶æ–‡ä»¶
        audio.export(input_path, format="wav")
        
        # 3. è°ƒç”¨ FFmpeg çš„æ ¸æ­¦å™¨ï¼šloudnorm æ»¤é•œ
        # I=-16:   ç›®æ ‡å“åº¦ -16 LUFS (æ’­å®¢é»„é‡‘æ ‡å‡†)
        # LRA=11:  å“åº¦èŒƒå›´ 11 LU (äººå£°å¯¹è¯çš„æ ‡å‡†åŠ¨æ€èŒƒå›´)
        # TP=-1.5: çœŸå³°å€¼ -1.5 dBTP (é˜²æ­¢çˆ†éŸ³)
        command = [
            "ffmpeg",
            "-y",                     # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            "-i", input_path,         # è¾“å…¥
            "-af", "loudnorm=I=-16:LRA=11:TP=-1.5",  # æ ¸å¿ƒæ»¤é•œ
            "-ar", "44100",           # ç»Ÿä¸€é‡‡æ ·ç‡
            output_path               # è¾“å‡º
        ]
        
        try:
            # æ‰§è¡Œå‘½ä»¤ï¼ˆä¸æ˜¾ç¤ºç¹æ‚çš„æ—¥å¿—ï¼‰
            subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
            # 4. æŠŠå¤„ç†å¥½çš„éŸ³é¢‘è¯»å›æ¥
            processed_audio = AudioSegment.from_wav(output_path)
            
        except subprocess.CalledProcessError as e:
            print("FFmpeg error:", e)
            # å¦‚æœå¤±è´¥äº†ï¼Œå°±è¿”å›åŸéŸ³é¢‘ï¼ˆæˆ–è€…åšä¸€ä¸ªç®€å•çš„å½’ä¸€åŒ–ä½œä¸ºä¿åº•ï¼‰
            processed_audio = normalize(audio)
            
        finally:
            # 5. æ¸…ç†æˆ˜åœºï¼šåˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(input_path):
                os.remove(input_path)
            if os.path.exists(output_path):
                os.remove(output_path)
                
    return processed_audio

def go_to_stage_1():
    state['original_file'] = None
    with state['main_card']:
        state['main_card'].clear()
        with ui.column().classes('w-full items-center gap-8 p-12'):
            ui.label('ğŸµ Audio Processor').classes('text-5xl font-light text-gray-800')
            ui.label('Upload audio to begin').classes('text-xl text-gray-600 font-light')
            ui.upload(on_upload=handle_upload, auto_upload=True, max_files=1).props('accept="audio/*"').classes('w-full max-w-md')

def handle_upload(event):
    state['original_file'] = event.content.read() # CRITICAL FIX
    state['original_filename'] = event.name
    ui.notify(f"Uploaded: {event.name}")
    go_to_stage_2()

def go_to_stage_2():
    with state['main_card']:
        state['main_card'].clear()
        with ui.column().classes('w-full items-center gap-8 p-12'):
            ui.label('Select Tool').classes('text-4xl font-light text-gray-800')
            if state['original_file']:
                b64 = base64.b64encode(state['original_file']).decode()
                ui.html(f'<audio controls src="data:audio/mp3;base64,{b64}" class="w-full max-w-md mb-8"></audio>')
            with ui.row().classes('gap-6'):
                ui.button('ğŸ› ï¸ Sound Rescue', on_click=lambda: process_audio('rescue')).classes('text-xl px-12 py-8 rounded-2xl shadow-lg').style('background: #667eea; color: white;')
                ui.button('âš–ï¸ Dynamic Balance', on_click=lambda: process_audio('balance')).classes('text-xl px-12 py-8 rounded-2xl shadow-lg').style('background: #f093fb; color: white;')

async def process_audio(tool_type: str):
    notification = ui.notification('Processing...', type='ongoing', spinner=True)
    try:
        loop = asyncio.get_running_loop()
        def run_pydub():
            audio = AudioSegment.from_file(io.BytesIO(state['original_file']))
            processed = process_sound_rescue(audio) if tool_type == 'rescue' else process_dynamic_balance(audio)
            buffer = io.BytesIO()
            processed.export(buffer, format="mp3")
            buffer.seek(0)
            return buffer.read()
        
        state['processed_file'] = await loop.run_in_executor(None, run_pydub)
        state['processed_filename'] = f"processed_{state['original_filename']}"
        notification.dismiss()
        go_to_stage_3()
    except Exception as e:
        notification.dismiss()
        ui.notify(f'Error: {str(e)}', type='negative')

def go_to_stage_3():
    with state['main_card']:
        state['main_card'].clear()
        with ui.column().classes('w-full items-center gap-8 p-12'):
            ui.label('âœ¨ Ready').classes('text-4xl font-light text-gray-800')
            b64 = base64.b64encode(state['processed_file']).decode()
            ui.html(f'<audio controls src="data:audio/mp3;base64,{b64}" class="w-full max-w-md mb-8"></audio>')
            ui.button('â¬‡ï¸ Download', on_click=lambda: download_bytes(state['processed_file'], state['processed_filename'])).classes('text-2xl px-16 py-8 rounded-2xl shadow-xl').style('background: #11998e; color: white;')
            ui.button('ğŸ”„ Start Over', on_click=go_to_stage_1).classes('flat')

@ui.page('/')
def main_page():
    ui.query('body').style('background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%); min-height: 100vh; display: flex; align-items: center; justify-content: center;')
    with ui.card().classes('backdrop-blur-xl bg-white/70 rounded-3xl shadow-2xl').style('width: 900px; min-height: 600px;') as main_card:
        state['main_card'] = main_card
        go_to_stage_1()

ui.run(title='Audio Processor', port=8082, reload=False)